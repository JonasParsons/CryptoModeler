{
    "lstm_units_1": 128,
    "lstm_units_2": 128,
    "dropout": 0.5,
    "learning_rate": 0.0009559214238176964,
    "batch_size": 32,
    "dense_units": 16,
    "sequence_length": 10,
    "gradient_clipping": 2.0,
    "optimizer": "adam",
    "activation": "tanh",
    "num_indicators": 6,
    "scaler_type": "RobustScaler"
}